{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Contrast coding\n",
    "\n",
    "## What and why?\n",
    "\n",
    "To fit any kind of statistical model you need some kind of *numerical\n",
    "representation* of your data. Data often comes in a *table*, a named\n",
    "collection of variables of different types of data. Some of that data is\n",
    "\"continuous\", or basically numeric. But often our data is not numeric\n",
    "(or continuous), but \"categorical\", having a finite number of distinct\n",
    "levels.\n",
    "\n",
    "For instance, let's look at the KB07 dataset:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 44,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<table class=\"data-frame\"><thead><tr><th></th><th>subj</th><th>item</th><th>spkr</th><th>prec</th><th>load</th><th>rt_trunc</th><th>rt_raw</th></tr><tr><th></th><th>String</th><th>String</th><th>String</th><th>String</th><th>String</th><th>Int16</th><th>Int16</th></tr></thead><tbody><p>5 rows × 7 columns</p><tr><th>1</th><td>S030</td><td>I01</td><td>new</td><td>break</td><td>yes</td><td>2267</td><td>2267</td></tr><tr><th>2</th><td>S030</td><td>I02</td><td>old</td><td>maintain</td><td>no</td><td>3856</td><td>3856</td></tr><tr><th>3</th><td>S030</td><td>I03</td><td>old</td><td>break</td><td>no</td><td>1567</td><td>1567</td></tr><tr><th>4</th><td>S030</td><td>I04</td><td>new</td><td>maintain</td><td>no</td><td>1732</td><td>1732</td></tr><tr><th>5</th><td>S030</td><td>I05</td><td>new</td><td>break</td><td>no</td><td>2660</td><td>2660</td></tr></tbody></table>"
      ],
      "text/latex": [
       "\\begin{tabular}{r|ccccccc}\n",
       "\t& subj & item & spkr & prec & load & rt\\_trunc & rt\\_raw\\\\\n",
       "\t\\hline\n",
       "\t& String & String & String & String & String & Int16 & Int16\\\\\n",
       "\t\\hline\n",
       "\t1 & S030 & I01 & new & break & yes & 2267 & 2267 \\\\\n",
       "\t2 & S030 & I02 & old & maintain & no & 3856 & 3856 \\\\\n",
       "\t3 & S030 & I03 & old & break & no & 1567 & 1567 \\\\\n",
       "\t4 & S030 & I04 & new & maintain & no & 1732 & 1732 \\\\\n",
       "\t5 & S030 & I05 & new & break & no & 2660 & 2660 \\\\\n",
       "\\end{tabular}\n"
      ],
      "text/plain": [
       "5×7 DataFrame\n",
       "│ Row │ subj   │ item   │ spkr   │ prec     │ load   │ rt_trunc │ rt_raw │\n",
       "│     │ \u001b[90mString\u001b[39m │ \u001b[90mString\u001b[39m │ \u001b[90mString\u001b[39m │ \u001b[90mString\u001b[39m   │ \u001b[90mString\u001b[39m │ \u001b[90mInt16\u001b[39m    │ \u001b[90mInt16\u001b[39m  │\n",
       "├─────┼────────┼────────┼────────┼──────────┼────────┼──────────┼────────┤\n",
       "│ 1   │ S030   │ I01    │ new    │ break    │ yes    │ 2267     │ 2267   │\n",
       "│ 2   │ S030   │ I02    │ old    │ maintain │ no     │ 3856     │ 3856   │\n",
       "│ 3   │ S030   │ I03    │ old    │ break    │ no     │ 1567     │ 1567   │\n",
       "│ 4   │ S030   │ I04    │ new    │ maintain │ no     │ 1732     │ 1732   │\n",
       "│ 5   │ S030   │ I05    │ new    │ break    │ no     │ 2660     │ 2660   │"
      ]
     },
     "execution_count": 44,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "using DataFrames, DataFramesMeta\n",
    "using MixedModels, GLM\n",
    "using LinearAlgebra\n",
    "\n",
    "kb07 = MixedModels.dataset(:kb07)\n",
    "first(kb07, 5)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Here `:spkr`, `:prec`, and `:load` are categortical variables, each of\n",
    "which takes on two different values. If we fit a regression using this\n",
    "dataset, we end up with predictors that refer to specific levels:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 45,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Linear mixed model fit by maximum likelihood\n",
       " rt_trunc ~ 1 + spkr + prec + spkr & prec + (1 | subj)\n",
       "     logLik        -2 logLik          AIC             BIC       \n",
       " -1.45767208×10⁴  2.91534417×10⁴  2.91654417×10⁴  2.91983781×10⁴\n",
       "\n",
       "Variance components:\n",
       "            Column    Variance  Std.Dev. \n",
       "subj     (Intercept)   95885.39 309.65366\n",
       "Residual              662657.47 814.03776\n",
       " Number of obs: 1789; levels of grouping factors: 56\n",
       "\n",
       "  Fixed-effects parameters:\n",
       "──────────────────────────────────────────────────────────────────\n",
       "                             Estimate  Std.Error  z value  P(>|z|)\n",
       "──────────────────────────────────────────────────────────────────\n",
       "(Intercept)                 2425.32      56.5224    42.91   <1e-99\n",
       "spkr: old                    179.992     54.4214     3.31   0.0009\n",
       "prec: maintain              -623.347     54.4214   -11.45   <1e-29\n",
       "spkr: old & prec: maintain   -86.7763    76.9856    -1.13   0.2597\n",
       "──────────────────────────────────────────────────────────────────"
      ]
     },
     "execution_count": 45,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "f = @formula(rt_trunc ~ 1 + spkr + prec + spkr&prec + (1 | subj))\n",
    "mod = fit(MixedModel, f, kb07)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Let's look at a few rows of the fixed effects design matrix that's\n",
    "generated for this model:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 46,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "5×4 Array{Int64,2}:\n",
       " 1  0  0  0\n",
       " 1  1  1  1\n",
       " 1  1  0  0\n",
       " 1  0  1  0\n",
       " 1  0  0  0"
      ]
     },
     "execution_count": 46,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "Int.(mod.X)[1:5, :]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "A few things to note: all the values are 0 or 1, and there's one column\n",
    "of all 1s at the start (that's the `(Intercept)` term). Columns 2 and 3\n",
    "correspond to `spkr` and `prec`: there's a 0 where `spkr == \"new\"` and a\n",
    "1 for `\"old\"`. Note that the coefficient name for this column is `spkr:\n",
    "old`, which indicates that this predictor indicates the presence of\n",
    "\"old\", relative to the (implicit) baseline of \"new\". Similarly for\n",
    "`prec: maintain`.\n",
    "\n",
    "The last column is the interaction term `spkr&prec`, and it's the\n",
    "elementwise product of the columns for `spkr: new` and `pred: maintain`."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 47,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<table class=\"data-frame\"><thead><tr><th></th><th>subj</th><th>item</th><th>spkr</th><th>prec</th><th>load</th><th>rt_trunc</th><th>rt_raw</th></tr><tr><th></th><th>String</th><th>String</th><th>String</th><th>String</th><th>String</th><th>Int16</th><th>Int16</th></tr></thead><tbody><p>5 rows × 7 columns</p><tr><th>1</th><td>S030</td><td>I01</td><td>new</td><td>break</td><td>yes</td><td>2267</td><td>2267</td></tr><tr><th>2</th><td>S030</td><td>I02</td><td>old</td><td>maintain</td><td>no</td><td>3856</td><td>3856</td></tr><tr><th>3</th><td>S030</td><td>I03</td><td>old</td><td>break</td><td>no</td><td>1567</td><td>1567</td></tr><tr><th>4</th><td>S030</td><td>I04</td><td>new</td><td>maintain</td><td>no</td><td>1732</td><td>1732</td></tr><tr><th>5</th><td>S030</td><td>I05</td><td>new</td><td>break</td><td>no</td><td>2660</td><td>2660</td></tr></tbody></table>"
      ],
      "text/latex": [
       "\\begin{tabular}{r|ccccccc}\n",
       "\t& subj & item & spkr & prec & load & rt\\_trunc & rt\\_raw\\\\\n",
       "\t\\hline\n",
       "\t& String & String & String & String & String & Int16 & Int16\\\\\n",
       "\t\\hline\n",
       "\t1 & S030 & I01 & new & break & yes & 2267 & 2267 \\\\\n",
       "\t2 & S030 & I02 & old & maintain & no & 3856 & 3856 \\\\\n",
       "\t3 & S030 & I03 & old & break & no & 1567 & 1567 \\\\\n",
       "\t4 & S030 & I04 & new & maintain & no & 1732 & 1732 \\\\\n",
       "\t5 & S030 & I05 & new & break & no & 2660 & 2660 \\\\\n",
       "\\end{tabular}\n"
      ],
      "text/plain": [
       "5×7 DataFrame\n",
       "│ Row │ subj   │ item   │ spkr   │ prec     │ load   │ rt_trunc │ rt_raw │\n",
       "│     │ \u001b[90mString\u001b[39m │ \u001b[90mString\u001b[39m │ \u001b[90mString\u001b[39m │ \u001b[90mString\u001b[39m   │ \u001b[90mString\u001b[39m │ \u001b[90mInt16\u001b[39m    │ \u001b[90mInt16\u001b[39m  │\n",
       "├─────┼────────┼────────┼────────┼──────────┼────────┼──────────┼────────┤\n",
       "│ 1   │ S030   │ I01    │ new    │ break    │ yes    │ 2267     │ 2267   │\n",
       "│ 2   │ S030   │ I02    │ old    │ maintain │ no     │ 3856     │ 3856   │\n",
       "│ 3   │ S030   │ I03    │ old    │ break    │ no     │ 1567     │ 1567   │\n",
       "│ 4   │ S030   │ I04    │ new    │ maintain │ no     │ 1732     │ 1732   │\n",
       "│ 5   │ S030   │ I05    │ new    │ break    │ no     │ 2660     │ 2660   │"
      ]
     },
     "execution_count": 47,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "kb07[1:5, :]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## How to take control\n",
    "\n",
    "You can set your own contrasts via the `contrasts=` keyword argument in\n",
    "`fit`, with the variable you want to code as the key and contrasts as\n",
    "the value:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 48,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Linear mixed model fit by maximum likelihood\n",
       " rt_trunc ~ 1 + spkr + prec + spkr & prec + (1 | subj)\n",
       "     logLik        -2 logLik          AIC             BIC       \n",
       " -1.45767208×10⁴  2.91534417×10⁴  2.91654417×10⁴  2.91983781×10⁴\n",
       "\n",
       "Variance components:\n",
       "            Column    Variance  Std.Dev. \n",
       "subj     (Intercept)   95885.39 309.65366\n",
       "Residual              662657.47 814.03776\n",
       " Number of obs: 1789; levels of grouping factors: 56\n",
       "\n",
       "  Fixed-effects parameters:\n",
       "───────────────────────────────────────────────────────────────\n",
       "                          Estimate  Std.Error  z value  P(>|z|)\n",
       "───────────────────────────────────────────────────────────────\n",
       "(Intercept)              1848.58      49.5329    37.32   <1e-99\n",
       "spkr: new                 -46.6081    27.2263    -1.71   0.0869\n",
       "prec: break               666.735     38.4928    17.32   <1e-66\n",
       "spkr: new & prec: break   -43.3882    38.4928    -1.13   0.2597\n",
       "───────────────────────────────────────────────────────────────"
      ]
     },
     "execution_count": 48,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "using StatsModels\n",
    "\n",
    "contrasts = Dict(\n",
    "    :spkr => EffectsCoding(base = \"old\"),\n",
    "    :prec => DummyCoding(levels = [\"maintain\", \"break\"])\n",
    ")\n",
    "\n",
    "mod2 = fit(MixedModel, f, kb07, contrasts=contrasts)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "This example illustrates two ways to control the ordering of levels used\n",
    "to compute the contrasts:\n",
    "\n",
    "1.  you can use `base=` to determine the baseline level\n",
    "2.  you can use `levels=` to indicate all the levels that are used in\n",
    "    the contrasts, the first of which is automatically set as the\n",
    "    baseline.\n",
    "\n",
    "## Built in contrast coding schemes\n",
    "\n",
    "StatsModels.jl provides a few commonly used contrast coding schemes,\n",
    "some less-commonly used schemes, and structs that allow you to manually\n",
    "specify your own, custom schemes.\n",
    "\n",
    "All are subtypes of the `AbstractContrasts` type:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 49,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "7-element Array{Any,1}:\n",
       " ContrastsCoding            \n",
       " DummyCoding                \n",
       " EffectsCoding              \n",
       " HelmertCoding              \n",
       " HypothesisCoding           \n",
       " SeqDiffCoding              \n",
       " StatsModels.FullDummyCoding"
      ]
     },
     "execution_count": 49,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "using InteractiveUtils\n",
    "subtypes(AbstractContrasts)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "And all have fairly extensive documentation via the normal help system.\n",
    "For instance:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 50,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "1-element Array{Any,1}:\n",
       " ```\n",
       "SeqDiffCoding([base[, levels]])\n",
       "```\n",
       "\n",
       "Code each level in order to test \"sequential difference\" hypotheses, which compares each level to the level below it (starting with the second level). Specifically, the $n$th predictor tests the hypothesis that the difference between levels $n$ and $n+1$ is zero.\n",
       "\n",
       "# Examples\n",
       "\n",
       "```jldoctest seqdiff\n",
       "julia> seqdiff = StatsModels.ContrastsMatrix(SeqDiffCoding(), [\"a\", \"b\", \"c\", \"d\"]).matrix\n",
       "4×3 Array{Float64,2}:\n",
       " -0.75  -0.5  -0.25\n",
       "  0.25  -0.5  -0.25\n",
       "  0.25   0.5  -0.25\n",
       "  0.25   0.5   0.75\n",
       "```\n",
       "\n",
       "The interpretation of sequential difference coding may be hard to see from the contrasts matrix itself.  The corresponding hypothesis matrix shows a clearer picture.  From the rows of the hypothesis matrix, we can see that these contrasts test the difference between the first and second levels, the second and third, and the third and fourth, respectively:\n",
       "\n",
       "```jldoctest seqdiff\n",
       "julia> round.(pinv(seqdiff), digits=2)\n",
       "3×4 Array{Float64,2}:\n",
       " -1.0   1.0  -0.0   0.0\n",
       " -0.0  -1.0   1.0  -0.0\n",
       "  0.0  -0.0  -1.0   1.0\n",
       "```\n"
      ]
     },
     "execution_count": 50,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# use ?SeqDiffCoding in the REPL\n",
    "(@doc SeqDiffCoding).content"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Standard contrasts\n",
    "\n",
    "The most commonly used contrasts are `DummyCoding` and `EffectsCoding`\n",
    "(which are similar to `contr.treatment` and `contr.sum` in R,\n",
    "respectively).\n",
    "\n",
    "### \"Exotic\" contrasts\n",
    "\n",
    "We also provide `HelmertCoding` and `SeqDiffCoding` (corresponding to\n",
    "base R's `contr.helmert` and MASS's `contr.sdiff`).\n",
    "\n",
    "### Manual contrasts\n",
    "\n",
    "There are two ways to manually specify contrasts. First, you can specify\n",
    "them **directly** via `ContrastsCoding`. If you do, it's good practice\n",
    "to specify the levels corresponding to the rows of the matrix, although\n",
    "they can be omitted in which case they'll be inferred from the data.\n",
    "\n",
    "For instance, here's a weird set of contrasts for `:spkr`:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 51,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Linear mixed model fit by maximum likelihood\n",
       " rt_trunc ~ 1 + spkr + prec + spkr & prec + (1 | subj)\n",
       "     logLik        -2 logLik          AIC             BIC       \n",
       " -1.45767208×10⁴  2.91534417×10⁴  2.91654417×10⁴  2.91983781×10⁴\n",
       "\n",
       "Variance components:\n",
       "            Column    Variance  Std.Dev. \n",
       "subj     (Intercept)   95885.39 309.65366\n",
       "Residual              662657.47 814.03776\n",
       " Number of obs: 1789; levels of grouping factors: 56\n",
       "\n",
       "  Fixed-effects parameters:\n",
       "──────────────────────────────────────────────────────────────────\n",
       "                             Estimate  Std.Error  z value  P(>|z|)\n",
       "──────────────────────────────────────────────────────────────────\n",
       "(Intercept)                 2545.31      50.3425    50.56   <1e-99\n",
       "spkr: new                   -179.992     54.4214    -3.31   0.0009\n",
       "prec: maintain              -681.198     40.582    -16.79   <1e-62\n",
       "spkr: new & prec: maintain    86.7763    76.9856     1.13   0.2597\n",
       "──────────────────────────────────────────────────────────────────"
      ]
     },
     "execution_count": 51,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "cs = Matrix([-1/3 2/3]')\n",
    "contr_manual = Dict(:spkr => StatsModels.ContrastsCoding(cs, levels=[\"old\", \"new\"]))\n",
    "mod3 = fit(MixedModel, f, kb07, contrasts=contr_manual)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "(Note that the estimates and even the signs of the fixed effect βs\n",
    "change when we change the contrasts, but the overall log-likelihood\n",
    "doesn't).\n",
    "\n",
    "We can see that the values from the contrasts matrix we specified are\n",
    "plugged directly in to the fixed effects matrix, and are also used in\n",
    "computing the predictor for the interaction:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 52,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "5×4 Array{Float64,2}:\n",
       " 1.0   0.666667  0.0   0.0     \n",
       " 1.0  -0.333333  1.0  -0.333333\n",
       " 1.0  -0.333333  0.0  -0.0     \n",
       " 1.0   0.666667  1.0   0.666667\n",
       " 1.0   0.666667  0.0   0.0     "
      ]
     },
     "execution_count": 52,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "mod3.X[1:5, :]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Contrasts from hypotheses\n",
    "\n",
    "A better way to specify manual contrasts is via `HypothesisCoding`,\n",
    "where each row of the matrix corresponds to the weights given to the\n",
    "cell means of the levels corresponding to each column (see [Schad et\n",
    "al. 2020](https://doi.org/10.1016/j.jml.2019.104038) for more\n",
    "information). This is less interesting with only two levels, so let's\n",
    "look at a scenario where we combine `:spkr` and `:prec` into a single,\n",
    "4-level predictor, and want to test some strange hypotheses."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 53,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Linear mixed model fit by maximum likelihood\n",
       " rt_trunc ~ 1 + spkr_prec + (1 | subj)\n",
       "     logLik        -2 logLik          AIC             BIC       \n",
       " -1.45767208×10⁴  2.91534417×10⁴  2.91654417×10⁴  2.91983781×10⁴\n",
       "\n",
       "Variance components:\n",
       "            Column    Variance  Std.Dev. \n",
       "subj     (Intercept)   95885.39 309.65366\n",
       "Residual              662657.47 814.03776\n",
       " Number of obs: 1789; levels of grouping factors: 56\n",
       "\n",
       "  Fixed-effects parameters:\n",
       "──────────────────────────────────────────────────────────────\n",
       "                         Estimate  Std.Error  z value  P(>|z|)\n",
       "──────────────────────────────────────────────────────────────\n",
       "(Intercept)              2425.32     56.5224    42.91   <1e-99\n",
       "spkr_prec: new-maintain  -623.347    54.4214   -11.45   <1e-29\n",
       "spkr_prec: old-break      179.992    54.4214     3.31   0.0009\n",
       "spkr_prec: old-maintain  -530.131    54.4839    -9.73   <1e-21\n",
       "──────────────────────────────────────────────────────────────"
      ]
     },
     "execution_count": 53,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "kb07ex = @transform(kb07, spkr_prec = :spkr .* \"-\" .* :prec);\n",
    "\n",
    "f2 = @formula(rt_trunc ~ 1 + spkr_prec + (1 | subj))\n",
    "mod4 = fit(MixedModel, f2, kb07ex)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Let's say we want to test whether the effect of `:prec` depends on\n",
    "whether `:spkr` is old vs. new. We need one contrast to test the\n",
    "hypothesis that `\"maintain\" != \"break\"` for \"new\", and another for\n",
    "\"old\". That leaves one over, to test the overall difference between\n",
    "\"new\" and \"old\"."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 54,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "3×4 Array{Float64,2}:\n",
       " -0.5  -0.5  0.5   0.5\n",
       "  0.0   0.0  1.0  -1.0\n",
       "  1.0  -1.0  0.0   0.0"
      ]
     },
     "execution_count": 54,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "levels = [\"new-break\", \"new-maintain\", \"old-break\", \"old-maintain\"]\n",
    "\n",
    "prec_old = (levels .== \"old-break\") .- (levels .== \"old-maintain\")\n",
    "prec_new = (levels .== \"new-break\") .- (levels .== \"new-maintain\")\n",
    "old_new = (abs.(prec_old) .- abs.(prec_new)) ./ 2\n",
    "\n",
    "contr_hyp = HypothesisCoding(Matrix(hcat(old_new, prec_old, prec_new)'),\n",
    "                             labels=[\"old\", \"(old) break\", \"(new) break\"])\n",
    "contr_hyp.hypotheses"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "These hypotheses correspond to the following *contrasts* (using the\n",
    "[`rationalize`](https://docs.julialang.org/en/v1/base/math/#Base.rationalize)\n",
    "function to make pretty fractions, like the `fractions` function in R):"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 55,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "4×3 Array{Rational{Int64},2}:\n",
       " -1//2   0//1   1//2\n",
       " -1//2   0//1  -1//2\n",
       "  1//2   1//2   0//1\n",
       "  1//2  -1//2   0//1"
      ]
     },
     "execution_count": 55,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "rationalize.(contr_hyp.contrasts, tol=1e-10)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Notice how the ±1 coding in the hypotheses (which translates into the difference\n",
    "between the mean response in those cells) is transformed into ±½ coding in the\n",
    "contrasts."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 56,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Linear mixed model fit by maximum likelihood\n",
       " rt_trunc ~ 1 + spkr_prec + (1 | subj)\n",
       "     logLik        -2 logLik          AIC             BIC       \n",
       " -1.45767208×10⁴  2.91534417×10⁴  2.91654417×10⁴  2.91983781×10⁴\n",
       "\n",
       "Variance components:\n",
       "            Column    Variance  Std.Dev. \n",
       "subj     (Intercept)   95885.39 309.65366\n",
       "Residual              662657.47 814.03776\n",
       " Number of obs: 1789; levels of grouping factors: 56\n",
       "\n",
       "  Fixed-effects parameters:\n",
       "─────────────────────────────────────────────────────────────\n",
       "                        Estimate  Std.Error  z value  P(>|z|)\n",
       "─────────────────────────────────────────────────────────────\n",
       "(Intercept)             2181.94     45.6362    47.81   <1e-99\n",
       "spkr_prec: old           136.604    38.4928     3.55   0.0004\n",
       "spkr_prec: (old) break   710.123    54.4527    13.04   <1e-38\n",
       "spkr_prec: (new) break   623.347    54.4214    11.45   <1e-29\n",
       "─────────────────────────────────────────────────────────────"
      ]
     },
     "execution_count": 56,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "mod5 = fit(MixedModel, f2, kb07ex, contrasts = Dict(:spkr_prec => contr_hyp))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Note that this is equivalent to the `/` \"nesting\" syntax using `EffectsCoding`,\n",
    "after adjusting for the 2× factor from the +1/-1 coding:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 57,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Linear mixed model fit by maximum likelihood\n",
       " rt_trunc ~ 1 + spkr + spkr & prec + (1 | subj)\n",
       "     logLik        -2 logLik          AIC             BIC       \n",
       " -1.45767208×10⁴  2.91534417×10⁴  2.91654417×10⁴  2.91983781×10⁴\n",
       "\n",
       "Variance components:\n",
       "            Column    Variance  Std.Dev. \n",
       "subj     (Intercept)   95885.39 309.65366\n",
       "Residual              662657.47 814.03776\n",
       " Number of obs: 1789; levels of grouping factors: 56\n",
       "\n",
       "  Fixed-effects parameters:\n",
       "───────────────────────────────────────────────────────────────\n",
       "                          Estimate  Std.Error  z value  P(>|z|)\n",
       "───────────────────────────────────────────────────────────────\n",
       "(Intercept)              2181.94      45.6362    47.81   <1e-99\n",
       "spkr: old                  68.3021    19.2464     3.55   0.0004\n",
       "spkr: new & prec: break   311.673     27.2107    11.45   <1e-29\n",
       "spkr: old & prec: break   355.062     27.2263    13.04   <1e-38\n",
       "───────────────────────────────────────────────────────────────"
      ]
     },
     "execution_count": 57,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "mod6 = fit(MixedModel,\n",
    "           @formula(rt_trunc ~ 1 + spkr/prec + (1|subj)), \n",
    "           kb07,\n",
    "           contrasts = Dict(:spkr => EffectsCoding(base=\"new\"),\n",
    "                            :prec => EffectsCoding(base=\"maintain\")))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# The `@formula`\n",
    "\n",
    "A formula in Julia is created with the `@formula` macro.  Between the macro and\n",
    "fitting a model, the formula goes through a number of steps.\n",
    "\n",
    "* The `@formula` macro itself does some transformations on the syntax, and\n",
    "  creates `Term`s\n",
    "* Then a `Schema` is extracted from the data, which says which `Term`s are\n",
    "  `ContinuousTerm`s and which are `CategoricalTerm`s\n",
    "* The `Schema` is then used to transform the original formula into a \"concrete\n",
    "  formula\".\n",
    "* The concrete formula (with all `Term`s replaced by continuous/categorical\n",
    "  versions) generates model matrix columns when given some data.\n",
    "\n",
    "The details are described in the\n",
    "[documentation](https://juliastats.org/StatsModels.jl/stable/internals/#The-lifecycle-of-a-@formula-1),\n",
    "and for the most part modeling packages handle these steps for you.  But in the\n",
    "interest of allowing you to do your own weird things, here are a few examples.\n",
    "\n",
    "## A formula is made of terms"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 58,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "FormulaTerm\n",
       "Response:\n",
       "  y(unknown)\n",
       "Predictors:\n",
       "  1\n",
       "  a(unknown)\n",
       "  b(unknown)\n",
       "  a(unknown) & b(unknown)"
      ]
     },
     "execution_count": 58,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "f = @formula(y ~ 1 + a + b + a&b)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "You can inpsect the internal structure with (it's like `str` in R):"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 59,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "FormulaTerm{Term,Tuple{ConstantTerm{Int64},Term,Term,InteractionTerm{Tuple{Term,Term}}}}\n",
      "  lhs: Term\n",
      "    sym: Symbol y\n",
      "  rhs: Tuple{ConstantTerm{Int64},Term,Term,InteractionTerm{Tuple{Term,Term}}}\n",
      "    1: ConstantTerm{Int64}\n",
      "      n: Int64 1\n",
      "    2: Term\n",
      "      sym: Symbol a\n",
      "    3: Term\n",
      "      sym: Symbol b\n",
      "    4: InteractionTerm{Tuple{Term,Term}}\n",
      "      terms: Tuple{Term,Term}\n",
      "        1: Term\n",
      "          sym: Symbol a\n",
      "        2: Term\n",
      "          sym: Symbol b\n"
     ]
    }
   ],
   "source": [
    "dump(f)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We can build the same formula directly, using terms:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 60,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Term\n",
      "  sym: Symbol a\n"
     ]
    }
   ],
   "source": [
    "t_a = term(:a)\n",
    "t_b = term(:b)\n",
    "t_1 = term(1)\n",
    "t_y = term(:y)\n",
    "\n",
    "dump(t_a)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 61,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "FormulaTerm\n",
       "Response:\n",
       "  y(unknown)\n",
       "Predictors:\n",
       "  1\n",
       "  a(unknown)\n",
       "  b(unknown)\n",
       "  a(unknown) & b(unknown)"
      ]
     },
     "execution_count": 61,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "f_dir = FormulaTerm(t_y, (t_1, t_a, t_b, InteractionTerm((t_a, t_b))))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Or, using operator overloading:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 62,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "FormulaTerm\n",
       "Response:\n",
       "  y(unknown)\n",
       "Predictors:\n",
       "  1\n",
       "  a(unknown)\n",
       "  b(unknown)\n",
       "  a(unknown) & b(unknown)"
      ]
     },
     "execution_count": 62,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "f_op = t_y ~ t_1 + t_a + t_b + t_a & t_b"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "These three are all equivalent:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 63,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "true"
      ]
     },
     "execution_count": 63,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "f == f_dir == f_op"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## The schema gives concrete terms\n",
    "\n",
    "If we have some fake data:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 64,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<table class=\"data-frame\"><thead><tr><th></th><th>y</th><th>a</th><th>b</th></tr><tr><th></th><th>Float64</th><th>Float64</th><th>Symbol</th></tr></thead><tbody><p>5 rows × 3 columns</p><tr><th>1</th><td>0.956405</td><td>0.338148</td><td>Q</td></tr><tr><th>2</th><td>0.929902</td><td>0.376832</td><td>R</td></tr><tr><th>3</th><td>0.747754</td><td>0.848059</td><td>S</td></tr><tr><th>4</th><td>0.573026</td><td>0.0967081</td><td>T</td></tr><tr><th>5</th><td>0.146775</td><td>0.92813</td><td>Q</td></tr></tbody></table>"
      ],
      "text/latex": [
       "\\begin{tabular}{r|ccc}\n",
       "\t& y & a & b\\\\\n",
       "\t\\hline\n",
       "\t& Float64 & Float64 & Symbol\\\\\n",
       "\t\\hline\n",
       "\t1 & 0.956405 & 0.338148 & Q \\\\\n",
       "\t2 & 0.929902 & 0.376832 & R \\\\\n",
       "\t3 & 0.747754 & 0.848059 & S \\\\\n",
       "\t4 & 0.573026 & 0.0967081 & T \\\\\n",
       "\t5 & 0.146775 & 0.92813 & Q \\\\\n",
       "\\end{tabular}\n"
      ],
      "text/plain": [
       "5×3 DataFrame\n",
       "│ Row │ y        │ a         │ b      │\n",
       "│     │ \u001b[90mFloat64\u001b[39m  │ \u001b[90mFloat64\u001b[39m   │ \u001b[90mSymbol\u001b[39m │\n",
       "├─────┼──────────┼───────────┼────────┤\n",
       "│ 1   │ 0.956405 │ 0.338148  │ Q      │\n",
       "│ 2   │ 0.929902 │ 0.376832  │ R      │\n",
       "│ 3   │ 0.747754 │ 0.848059  │ S      │\n",
       "│ 4   │ 0.573026 │ 0.0967081 │ T      │\n",
       "│ 5   │ 0.146775 │ 0.92813   │ Q      │"
      ]
     },
     "execution_count": 64,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df = DataFrame(y = rand(100), a = rand(100), b = repeat([:Q, :R, :S, :T], 25))\n",
    "first(df, 5)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We can extract a `Schema`:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 65,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "StatsModels.Schema with 3 entries:\n",
       "  a => a\n",
       "  y => y\n",
       "  b => b\n"
      ]
     },
     "execution_count": 65,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "sch = schema(df)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "This maps un-typed `Term`s to concrete verisons.  Now we know that `:a` is a\n",
    "continuous variable in this dataset:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 66,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "a(continuous)"
      ]
     },
     "execution_count": 66,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "sch[term(:a)]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Categorical terms hold the contrasts matrix and levels:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 67,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "b(DummyCoding:4→3)"
      ]
     },
     "execution_count": 67,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "t_b_concrete = sch[term(:b)]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 68,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "4×3 Array{Float64,2}:\n",
       " 0.0  0.0  0.0\n",
       " 1.0  0.0  0.0\n",
       " 0.0  1.0  0.0\n",
       " 0.0  0.0  1.0"
      ]
     },
     "execution_count": 68,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "cmat = t_b_concrete.contrasts\n",
    "cmat.matrix"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 69,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "4-element Array{Symbol,1}:\n",
       " :Q\n",
       " :R\n",
       " :S\n",
       " :T"
      ]
     },
     "execution_count": 69,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "cmat.levels"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## `apply_schema` combines terms and schema to get concrete versions\n",
    "\n",
    "The canonical case is to apply the schema to the whole formula:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 70,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "FormulaTerm\n",
       "Response:\n",
       "  y(continuous)\n",
       "Predictors:\n",
       "  1\n",
       "  a(continuous)\n",
       "  b(DummyCoding:4→3)\n",
       "  a(continuous) & b(DummyCoding:4→3)"
      ]
     },
     "execution_count": 70,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "apply_schema(f, sch)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Note that the schema gets pushed through the interaction term, too.\n",
    "\n",
    "We can also apply the schema to a single term:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 71,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "a(continuous) & b(DummyCoding:4→3)"
      ]
     },
     "execution_count": 71,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "apply_schema(term(:a) & term(:b), sch)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Of course if the schema doesn't have enough information, we'll get an error:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 72,
   "metadata": {},
   "outputs": [
    {
     "ename": "KeyError",
     "evalue": "KeyError: key argle_bargle not found",
     "output_type": "error",
     "traceback": [
      "KeyError: key argle_bargle not found",
      "",
      "Stacktrace:",
      " [1] getindex at ./dict.jl:477 [inlined]",
      " [2] getindex at /home/dave/.julia/packages/StatsModels/NakzS/src/schema.jl:48 [inlined]",
      " [3] apply_schema at /home/dave/.julia/packages/StatsModels/NakzS/src/schema.jl:212 [inlined]",
      " [4] apply_schema(::Term, ::StatsModels.Schema) at /home/dave/.julia/packages/StatsModels/NakzS/src/schema.jl:208",
      " [5] top-level scope at In[72]:1"
     ]
    }
   ],
   "source": [
    "apply_schema(term(:argle_bargle), sch)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Concrete terms generate arrays with `modelcols`\n",
    "\n",
    "Any term can generate model columns with `modelcols`:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 73,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "6×3 Array{Float64,2}:\n",
       " 0.0       0.0       0.0      \n",
       " 0.376832  0.0       0.0      \n",
       " 0.0       0.848059  0.0      \n",
       " 0.0       0.0       0.0967081\n",
       " 0.0       0.0       0.0      \n",
       " 0.211993  0.0       0.0      "
      ]
     },
     "execution_count": 73,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "t_ab_concrete = apply_schema(term(:a) & term(:b), sch)\n",
    "modelcols(t_ab_concrete, first(df, 6))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Compare with:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 74,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "t_ab_concrete_formula = f_concrete.rhs.terms[end] = a & b\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "6×3 Array{Float64,2}:\n",
       " 0.0       0.0       0.0      \n",
       " 0.376832  0.0       0.0      \n",
       " 0.0       0.848059  0.0      \n",
       " 0.0       0.0       0.0967081\n",
       " 0.0       0.0       0.0      \n",
       " 0.211993  0.0       0.0      "
      ]
     },
     "execution_count": 74,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "f_concrete = apply_schema(f, sch)\n",
    "@show t_ab_concrete_formula = f_concrete.rhs.terms[end]\n",
    "modelcols(t_ab_concrete_formula, first(df, 6))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Of course you can generate columns for the whole formula (it returns a tuple of\n",
    "left-hand side, right-hand side columns):"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 75,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "6×8 Array{Float64,2}:\n",
       " 1.0  0.338148   0.0  0.0  0.0  0.0       0.0       0.0      \n",
       " 1.0  0.376832   1.0  0.0  0.0  0.376832  0.0       0.0      \n",
       " 1.0  0.848059   0.0  1.0  0.0  0.0       0.848059  0.0      \n",
       " 1.0  0.0967081  0.0  0.0  1.0  0.0       0.0       0.0967081\n",
       " 1.0  0.92813    0.0  0.0  0.0  0.0       0.0       0.0      \n",
       " 1.0  0.211993   1.0  0.0  0.0  0.211993  0.0       0.0      "
      ]
     },
     "execution_count": 75,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "y, X = modelcols(f_concrete, first(df, 6))\n",
    "X"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Predicting based on new data\n",
    "\n",
    "Any table with the right columns can be passed to `modelcols` and the right\n",
    "columns are generated, even if some levels are missing:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 76,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "5×8 Array{Float64,2}:\n",
       " 1.0  0.800447    1.0  0.0  0.0  0.800447  0.0         0.0\n",
       " 1.0  0.573827    1.0  0.0  0.0  0.573827  0.0         0.0\n",
       " 1.0  0.801419    0.0  0.0  0.0  0.0       0.0         0.0\n",
       " 1.0  0.00118095  0.0  1.0  0.0  0.0       0.00118095  0.0\n",
       " 1.0  0.27748     1.0  0.0  0.0  0.27748   0.0         0.0"
      ]
     },
     "execution_count": 76,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df2 = DataFrame(a = rand(5), b = [:R, :R, :Q, :S, :R])\n",
    "modelcols(f_concrete.rhs, df2)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Use a named tuple for a single row\n",
    "\n",
    "A single row of the model matrix can be generated from a `NamedTuple` of data:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 77,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "8-element Array{Float64,1}:\n",
       " 1.0\n",
       " 1.5\n",
       " 0.0\n",
       " 0.0\n",
       " 1.0\n",
       " 0.0\n",
       " 0.0\n",
       " 1.5"
      ]
     },
     "execution_count": 77,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "data_row = (a = 1.5, b = :T)\n",
    "modelcols(f_concrete.rhs, data_row)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Get coefficient names for any term with `coefnames`"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 78,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(\"y\", [\"(Intercept)\", \"a\", \"b: R\", \"b: S\", \"b: T\", \"a & b: R\", \"a & b: S\", \"a & b: T\"])"
      ]
     },
     "execution_count": 78,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "coefnames(f_concrete)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 79,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "3-element Array{String,1}:\n",
       " \"a & b: R\"\n",
       " \"a & b: S\"\n",
       " \"a & b: T\""
      ]
     },
     "execution_count": 79,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "coefnames(f_concrete.rhs.terms[end])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 80,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "3-element Array{String,1}:\n",
       " \"b: R\"\n",
       " \"b: S\"\n",
       " \"b: T\""
      ]
     },
     "execution_count": 80,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "coefnames(sch[term(:b)])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Formula syntax\n",
    "\n",
    "The formula syntax is very similar to R, with the exception that an interaction\n",
    "is specified with `&`, and that some R syntax is not supported by default (`^`,\n",
    "`/` outside of MixedModels.jl).\n",
    "\n",
    "### Non-special calls \n",
    "\n",
    "Any function calls that are not special syntax (`+`, `&`, `*`, and `~`) are\n",
    "treated as normal julia code, so you can write things like"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 81,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "FormulaTerm\n",
       "Response:\n",
       "  (y)->log(y)\n",
       "Predictors:\n",
       "  1\n",
       "  a(unknown)\n",
       "  (a)->a ^ 2\n",
       "  b(unknown)\n",
       "  a(unknown) & b(unknown)\n",
       "  (a)->a ^ 2 & b(unknown)"
      ]
     },
     "execution_count": 81,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "f2 = @formula(log(y) ~ 1 + (a + a^2) * b)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 82,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "FormulaTerm\n",
       "Response:\n",
       "  (y)->log(y)\n",
       "Predictors:\n",
       "  1\n",
       "  a(continuous)\n",
       "  (a)->a ^ 2\n",
       "  b(DummyCoding:4→3)\n",
       "  a(continuous) & b(DummyCoding:4→3)\n",
       "  (a)->a ^ 2 & b(DummyCoding:4→3)"
      ]
     },
     "execution_count": 82,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "f2_concrete = apply_schema(f2, sch)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 83,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "([-0.04457330177727352, -0.07267575264362239, -0.2906812305720375, -0.5568250412666073, -1.918851244049599], [1.0 0.3381483054241785 … 0.0 0.0; 1.0 0.3768317547009774 … 0.0 0.0; … ; 1.0 0.09670814004285089 … 0.0 0.00935246435054766; 1.0 0.9281295827279596 … 0.0 0.0])"
      ]
     },
     "execution_count": 83,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "y2, X2 = modelcols(f2_concrete, first(df, 5))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 84,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "true"
      ]
     },
     "execution_count": 84,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "y2 == log.(df[1:5, :y])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 85,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "5×12 Array{Float64,2}:\n",
       " 1.0  0.338148   0.114344    0.0  0.0  0.0  …  0.0       0.0       0.0       \n",
       " 1.0  0.376832   0.142002    1.0  0.0  0.0     0.142002  0.0       0.0       \n",
       " 1.0  0.848059   0.719203    0.0  1.0  0.0     0.0       0.719203  0.0       \n",
       " 1.0  0.0967081  0.00935246  0.0  0.0  1.0     0.0       0.0       0.00935246\n",
       " 1.0  0.92813    0.861425    0.0  0.0  0.0     0.0       0.0       0.0       "
      ]
     },
     "execution_count": 85,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "X2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 86,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "12-element Array{String,1}:\n",
       " \"(Intercept)\" \n",
       " \"a\"           \n",
       " \"a ^ 2\"       \n",
       " \"b: R\"        \n",
       " \"b: S\"        \n",
       " \"b: T\"        \n",
       " \"a & b: R\"    \n",
       " \"a & b: S\"    \n",
       " \"a & b: T\"    \n",
       " \"a ^ 2 & b: R\"\n",
       " \"a ^ 2 & b: S\"\n",
       " \"a ^ 2 & b: T\""
      ]
     },
     "execution_count": 86,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "coefnames(f2_concrete.rhs)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Advanced: making the ordinary special\n",
    "\n",
    "You may have noticed that `zercocorr` and `|` were not included in the list of\n",
    "special syntax above.  StatsModels.jl provides a method to add special syntax\n",
    "for the `@formula` that's specific to certain models.  This works using the\n",
    "standard Julia techniques of multiple dispatch, by providing methods that\n",
    "intercept `apply_schema` for particular combinations of functions, schema, and\n",
    "context (model type), like so:\n",
    "\n",
    "```\n",
    "function StatsModels.apply_schema(\n",
    "    t::FunctionTerm{typeof(|)},\n",
    "    schema::StatsModels.FullRank,\n",
    "    Mod::Type{<:MixedModel},\n",
    ")\n",
    "    schema = StatsModels.FullRank(schema.schema)\n",
    "    lhs, rhs = t.args_parsed\n",
    "    if !StatsModels.hasintercept(lhs) && !StatsModels.omitsintercept(lhs)\n",
    "        lhs = InterceptTerm{true}() + lhs\n",
    "    end\n",
    "    lhs, rhs = apply_schema.((lhs, rhs), Ref(schema), Mod)\n",
    "    RandomEffectsTerm(MatrixTerm(lhs), rhs)\n",
    "end\n",
    "```\n",
    "\n",
    "There's a simpler [example in the StatsModels\n",
    "docs](https://juliastats.org/StatsModels.jl/stable/internals/#An-example-of-custom-syntax:-poly-1)\n",
    "which adds a `poly(x, n)` syntax for polynomial regression."
   ]
  }
 ],
 "metadata": {
  "@webio": {
   "lastCommId": "3b5dd4414d6748b39de1cc1c08497e09",
   "lastKernelId": "b0fd98fd-005c-4b43-9576-ebd066dd5588"
  },
  "kernelspec": {
   "display_name": "Julia 1.3.0",
   "language": "julia",
   "name": "julia-1.3"
  },
  "language_info": {
   "file_extension": ".jl",
   "mimetype": "application/julia",
   "name": "julia",
   "version": "1.3.0"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
