#+TITLE: Contrasts and @formula in StatsModels.jl


* Contrast coding
  :PROPERTIES:
  :header-args: :async yes :kernel julia-1.3 :session jl-contrasts :display text/plain text/html
  :END:

** What and why?

To fit any kind of statistical model you need some kind of /numerical
representation/ of your data.  Data often comes in a /table/, a named collection
of variables of different types of data.  Some of that data is "continuous", or
basically numeric.  But often our data is not numeric (or continuous), but
"categorical", having a finite number of distinct levels.

For instance, let's look at the KB07 dataset:

#+begin_src jupyter-julia
  using DataFrames, MixedModels, GLM

  kb07 = MixedModels.dataset(:kb07)

#+end_src

#+RESULTS:
#+begin_example
  1789Ã—7 DataFrame
  â”‚ Row  â”‚ subj   â”‚ item   â”‚ spkr   â”‚ prec     â”‚ load   â”‚ rt_trunc â”‚ rt_raw â”‚
  â”‚      â”‚ [90mString[39m â”‚ [90mString[39m â”‚ [90mString[39m â”‚ [90mString[39m   â”‚ [90mString[39m â”‚ [90mInt16[39m    â”‚ [90mInt16[39m  â”‚
  â”œâ”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”¤
  â”‚ 1    â”‚ S030   â”‚ I01    â”‚ new    â”‚ break    â”‚ yes    â”‚ 2267     â”‚ 2267   â”‚
  â”‚ 2    â”‚ S030   â”‚ I02    â”‚ old    â”‚ maintain â”‚ no     â”‚ 3856     â”‚ 3856   â”‚
  â”‚ 3    â”‚ S030   â”‚ I03    â”‚ old    â”‚ break    â”‚ no     â”‚ 1567     â”‚ 1567   â”‚
  â”‚ 4    â”‚ S030   â”‚ I04    â”‚ new    â”‚ maintain â”‚ no     â”‚ 1732     â”‚ 1732   â”‚
  â”‚ 5    â”‚ S030   â”‚ I05    â”‚ new    â”‚ break    â”‚ no     â”‚ 2660     â”‚ 2660   â”‚
  â”‚ 6    â”‚ S030   â”‚ I06    â”‚ old    â”‚ maintain â”‚ yes    â”‚ 2763     â”‚ 2763   â”‚
  â”‚ 7    â”‚ S030   â”‚ I07    â”‚ old    â”‚ break    â”‚ yes    â”‚ 3528     â”‚ 3528   â”‚
  â”‚ 8    â”‚ S030   â”‚ I08    â”‚ new    â”‚ maintain â”‚ yes    â”‚ 1741     â”‚ 1741   â”‚
  â”‚ 9    â”‚ S030   â”‚ I09    â”‚ new    â”‚ break    â”‚ yes    â”‚ 3692     â”‚ 3692   â”‚
  â”‚ 10   â”‚ S030   â”‚ I10    â”‚ old    â”‚ maintain â”‚ no     â”‚ 1949     â”‚ 1949   â”‚
  â‹®
  â”‚ 1779 â”‚ S103   â”‚ I22    â”‚ new    â”‚ break    â”‚ no     â”‚ 1623     â”‚ 1623   â”‚
  â”‚ 1780 â”‚ S103   â”‚ I23    â”‚ old    â”‚ maintain â”‚ yes    â”‚ 2706     â”‚ 2706   â”‚
  â”‚ 1781 â”‚ S103   â”‚ I24    â”‚ old    â”‚ break    â”‚ yes    â”‚ 4281     â”‚ 4281   â”‚
  â”‚ 1782 â”‚ S103   â”‚ I25    â”‚ new    â”‚ maintain â”‚ yes    â”‚ 2075     â”‚ 2075   â”‚
  â”‚ 1783 â”‚ S103   â”‚ I26    â”‚ new    â”‚ break    â”‚ yes    â”‚ 3179     â”‚ 3179   â”‚
  â”‚ 1784 â”‚ S103   â”‚ I27    â”‚ old    â”‚ maintain â”‚ no     â”‚ 1216     â”‚ 1216   â”‚
  â”‚ 1785 â”‚ S103   â”‚ I28    â”‚ old    â”‚ break    â”‚ no     â”‚ 2286     â”‚ 2286   â”‚
  â”‚ 1786 â”‚ S103   â”‚ I29    â”‚ new    â”‚ maintain â”‚ no     â”‚ 1202     â”‚ 1202   â”‚
  â”‚ 1787 â”‚ S103   â”‚ I30    â”‚ new    â”‚ break    â”‚ no     â”‚ 1581     â”‚ 1581   â”‚
  â”‚ 1788 â”‚ S103   â”‚ I31    â”‚ old    â”‚ maintain â”‚ yes    â”‚ 1601     â”‚ 1601   â”‚
  â”‚ 1789 â”‚ S103   â”‚ I32    â”‚ old    â”‚ break    â”‚ yes    â”‚ 1941     â”‚ 1941   â”‚
#+end_example

Here ~:spkr~, ~:prec~, and ~:load~ are categortical variables, each of which
takes on two different values.  If we fit a regression using this dataset, we
end up with predictors that refer to specific levels:

#+begin_src jupyter-julia
  f = @formula(rt_trunc ~ 1 + spkr + prec + spkr&prec + (1 | subj))
  mod = fit(MixedModel, f, kb07)
#+end_src

#+RESULTS:
#+begin_example
  Linear mixed model fit by maximum likelihood
   rt_trunc ~ 1 + spkr + prec + spkr & prec + (1 | subj)
       logLik        -2 logLik          AIC             BIC       
   -1.45767208Ã—10â´  2.91534417Ã—10â´  2.91654417Ã—10â´  2.91983781Ã—10â´

  Variance components:
              Column    Variance  Std.Dev. 
  subj     (Intercept)   95885.39 309.65366
  Residual              662657.47 814.03776
   Number of obs: 1789; levels of grouping factors: 56

    Fixed-effects parameters:
  â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€
                               Estimate  Std.Error  z value  P(>|z|)
  â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€
  (Intercept)                 2425.32      56.5224    42.91   <1e-99
  spkr: old                    179.992     54.4214     3.31   0.0009
  prec: maintain              -623.347     54.4214   -11.45   <1e-29
  spkr: old & prec: maintain   -86.7763    76.9856    -1.13   0.2597
  â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€
#+end_example

Let's look at a few rows of the fixed effects design matrix that's generated for
this model:

#+begin_src jupyter-julia
  Int.(mod.X)[1:5, :]
#+end_src

#+RESULTS:
: 5Ã—4 Array{Int64,2}:
:  1  0  0  0
:  1  1  1  1
:  1  1  0  0
:  1  0  1  0
:  1  0  0  0

A few things to note: all the values are 0 or 1, and there's one column of all
1s at the start (that's the ~(Intercept)~ term).  Columns 2 and 3 correspond to
~spkr~ and ~prec~: there's a 0 where ~spkr == "new"~ and a 1 for ~"old"~.
Note that the coefficient name for this column is ~spkr: old~, which indicates
that this predictor indicates the presence of "old", relative to the (implicit)
baseline of "new".  Similarly for ~prec: maintain~.

The last column is the interaction term ~spkr&prec~, and it's the elementwise
product of the columns for ~spkr: new~ and ~pred: maintain~.

#+begin_src jupyter-julia
  kb07[1:5, :]
#+end_src

#+RESULTS:
: 5Ã—7 DataFrame
: â”‚ Row â”‚ subj   â”‚ item   â”‚ spkr   â”‚ prec     â”‚ load   â”‚ rt_trunc â”‚ rt_raw â”‚
: â”‚     â”‚ [90mString[39m â”‚ [90mString[39m â”‚ [90mString[39m â”‚ [90mString[39m   â”‚ [90mString[39m â”‚ [90mInt16[39m    â”‚ [90mInt16[39m  â”‚
: â”œâ”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”¤
: â”‚ 1   â”‚ S030   â”‚ I01    â”‚ new    â”‚ break    â”‚ yes    â”‚ 2267     â”‚ 2267   â”‚
: â”‚ 2   â”‚ S030   â”‚ I02    â”‚ old    â”‚ maintain â”‚ no     â”‚ 3856     â”‚ 3856   â”‚
: â”‚ 3   â”‚ S030   â”‚ I03    â”‚ old    â”‚ break    â”‚ no     â”‚ 1567     â”‚ 1567   â”‚
: â”‚ 4   â”‚ S030   â”‚ I04    â”‚ new    â”‚ maintain â”‚ no     â”‚ 1732     â”‚ 1732   â”‚
: â”‚ 5   â”‚ S030   â”‚ I05    â”‚ new    â”‚ break    â”‚ no     â”‚ 2660     â”‚ 2660   â”‚

** Controlling contrasts

You can set your own contrasts via the ~contrasts=~ keyword argument in ~fit~.

#+begin_src jupyter-julia
  using StatsModels

  contrasts = Dict(
      :spkr => EffectsCoding(base = "old"),
      :prec => DummyCoding(levels = ["maintain", "break"])
  )

  mod2 = fit(MixedModel, f, kb07, contrasts=contrasts)
#+end_src

#+RESULTS:
#+begin_example
  Linear mixed model fit by maximum likelihood
   rt_trunc ~ 1 + spkr + prec + spkr & prec + (1 | subj)
       logLik        -2 logLik          AIC             BIC       
   -1.45767208Ã—10â´  2.91534417Ã—10â´  2.91654417Ã—10â´  2.91983781Ã—10â´

  Variance components:
              Column    Variance  Std.Dev. 
  subj     (Intercept)   95885.39 309.65366
  Residual              662657.47 814.03776
   Number of obs: 1789; levels of grouping factors: 56

    Fixed-effects parameters:
  â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€
                            Estimate  Std.Error  z value  P(>|z|)
  â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€
  (Intercept)              1848.58      49.5329    37.32   <1e-99
  spkr: new                 -46.6081    27.2263    -1.71   0.0869
  prec: break               666.735     38.4928    17.32   <1e-66
  spkr: new & prec: break   -43.3882    38.4928    -1.13   0.2597
  â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€
#+end_example

This example illustrates two ways to control the ordering of levels used to
compute the contrasts: you can use ~base=~ to determine the baseline level, or
~levels=~ to indicate all the levels that are used in the contrasts.
